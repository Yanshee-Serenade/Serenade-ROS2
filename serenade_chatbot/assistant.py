"""
Voice assistant module for integrating ASR, LLM, and TTS with ROS2.

This module provides the VoiceAssistant class which integrates
speech recognition, LLM querying, and text-to-speech functionality
with ROS2 topic communication.
"""

import asyncio

import rclpy
from std_msgs.msg import String

from .asr import VoiceASR
from .tts import StreamTTS


class VoiceAssistant:
    """è¯­éŸ³åŠ©æ‰‹ - é›†æˆASRã€LLMã€TTS"""

    def __init__(self, segment_tts: bool = False):
        """
        Initialize voice assistant.

        Args:
            segment_tts: Whether to enable segmented TTS (sentence-based)
        """
        self.asr = VoiceASR()
        self.tts = StreamTTS()
        self.segment_tts = segment_tts
        self.is_running = False
        self.current_response = ""
        
        # ROS2 node and publishers/subscribers
        self.node = None
        self.question_publisher = None
        self.answer_subscriber = None

    def initialize_ros2(self, node):
        """Initialize ROS2 node and publishers/subscribers"""
        self.node = node
        self.question_publisher = node.create_publisher(String, 'question', 10)
        self.answer_subscriber = node.create_subscription(
            String,
            'answer',
            self.on_answer,
            10
        )

    def on_answer(self, msg: String):
        """Handle incoming answers from VLM server via ROS2 topic"""
        text_chunk = msg.data
        if text_chunk:
            self.current_response += text_chunk
            print(f"ğŸ¤– AI: {text_chunk}", flush=True)

            # å°†å“åº”æ·»åŠ åˆ°TTSé˜Ÿåˆ—
            asyncio.create_task(self.tts.add_text(text_chunk, interrupt=False))

    def start(self):
        """å¯åŠ¨è¯­éŸ³åŠ©æ‰‹"""
        self.is_running = True
        print("ğŸ¤ è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ï¼Œå¼€å§‹è¯´è¯å§...", flush=True)

        # å¯åŠ¨è¯­éŸ³è¯†åˆ«
        self.asr.start(self._on_speech_recognized)

    def stop(self):
        """åœæ­¢è¯­éŸ³åŠ©æ‰‹"""
        self.is_running = False
        self.asr.stop()
        print("ğŸ›‘ è¯­éŸ³åŠ©æ‰‹å·²åœæ­¢", flush=True)

    async def _on_speech_recognized(self, text: str):
        """å½“è¯­éŸ³è¢«è¯†åˆ«æ—¶çš„å›è°ƒ"""
        print(f"ğŸ—£ï¸ ä½ è¯´: {text}", flush=True)
        if "é—®ä½ " not in text:
            print("ğŸ‘€ å¦‚æœæé—®ï¼Œè¯·ä»¥â€œé—®ä½ â€å¼€å¤´ã€‚", flush=True)
            return

        # å¼‚æ­¥å¤„ç†LLMæŸ¥è¯¢
        await self._process_query(text)

    async def _process_query(self, text: str):
        """å¤„ç†æŸ¥è¯¢å¹¶ç”Ÿæˆå“åº”"""
        print("ğŸ¤” æ€è€ƒä¸­...", flush=True)
        self.current_response = ""

        # å‘å¸ƒé—®é¢˜åˆ°ROS2ä¸»é¢˜
        if self.question_publisher:
            msg = String()
            msg.data = f"""
            ä½ æ˜¯ä¸€ä¸ªäººå½¢æœºå™¨äººï¼Œå›¾ç‰‡æ˜¯ä½ ç°åœ¨çœ‹åˆ°çš„ç”»é¢ã€‚
            ä½ å¬åˆ°æœ‰äººè¯¢é—®ä½ ï¼šâ€œ{text}â€ã€‚è¿™æ˜¯ä½ è¯­éŸ³è¯†åˆ«æ¨¡å—ç»™å‡ºçš„ç»“æœï¼Œä½†æœ‰çš„å­—å¯èƒ½è¢«æ›¿æ¢ä¸ºäº†åŒéŸ³å­—ã€‚
            è¯·ç”¨ä¸€ä¸ªæ¯”è¾ƒäººç±»çš„è¯­æ°”å›ç­” Ta çš„é—®é¢˜ï¼Œä¸ç”¨å®³æ€•å†’çŠ¯åˆ°äººï¼Œä½ è¶Šåƒä¸€ä¸ªæœ‰æ€§æƒ…çš„çœŸäººå°±è¶Šå¥½ï¼Œ
            ä½†è¯·æ³¨æ„æŠŠæ¡åˆ†å¯¸å’Œåœºåˆï¼Œè¯·åƒä¸€ä¸ªçœŸäººä¸€æ ·ç®€çŸ­åœ°å›ç­”é—®é¢˜ï¼Œä¸ä¸ºè«åå…¶å¦™çš„é—®é¢˜å¤šè´¹å£èˆŒã€‚
            """
            self.question_publisher.publish(msg)
