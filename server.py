from flask import Flask, request, Response, jsonify
from flask_cors import CORS
from PIL import Image
from io import BytesIO
import torch
import json
import datetime
import os
import time
from threading import Thread
import numpy as np
import cv2
from transformers import AutoProcessor, AutoModelForImageTextToText
from transformers import TextIteratorStreamer
from depth_anything_3.api import DepthAnything3
from depth_anything_3.utils.visualize import visualize_depth
from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor
from sam3.visualization_utils import plot_results

# å¯¼å…¥ros_apiï¼ˆç¡®ä¿ros_api.pyä¸å½“å‰æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ï¼‰
import ros_api

# ===================== é…ç½®å¸¸é‡ï¼ˆæ¨¡å—åŒ–ï¼šç»Ÿä¸€ç®¡ç†é…ç½®ï¼‰ =====================
# æ¨¡å‹é…ç½®
MODEL_QWEN_8B = "Qwen/Qwen3-VL-8B-Instruct"
MODEL_QWEN_4B = "Qwen/Qwen3-VL-4B-Instruct"
MODEL_QWEN_2B = "Qwen/Qwen3-VL-2B-Instruct"
MODEL_SMOLVLM = "HuggingFaceTB/SmolVLM2-2.2B-Instruct"
MODEL_DA3_LARGE = "depth-anything/DA3-LARGE-1.1"
MODEL_VLM_DEFAULT = MODEL_QWEN_4B
MODEL_DA3_DEFAULT = MODEL_DA3_LARGE
MODEL_SAM3_PATH = "/home/seqn/sam3/sam3.pt"  # æ ¹æ®è‡ªå·±çš„æ¨¡å‹æƒé‡åœ°å€ä¿®æ”¹

# ç½‘ç»œé…ç½®
ROS_SERVER_IP = "127.0.0.1"
ROS_SERVER_PORT = 51121
FLASK_HOST = "0.0.0.0"
FLASK_PORT = 51122

# ç”Ÿæˆé…ç½®
MAX_NEW_TOKENS = 256
IMAGE_SAVE_PREFIX = "image_"

# ===================== å…¨å±€å¯¹è±¡ï¼ˆæ¨¡å—åŒ–ï¼šå»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…æå‰åŠ è½½ï¼‰ =====================
app = None
processor = None
model_vlm = None
model_da3 = None
processor_sam3 = None
tracking_client = None

# ===================== å›¾åƒå¤„ç†æ¨¡å—ï¼ˆæ¨¡å—åŒ–ï¼šç‹¬ç«‹å°è£…å›¾åƒç›¸å…³é€»è¾‘ï¼‰ =====================
def init_tracking_client() -> bool:
    """
    åˆå§‹åŒ–ros_apiè·Ÿè¸ªæ•°æ®å®¢æˆ·ç«¯ï¼ˆæ¨¡å—åŒ–ï¼šå°è£…å®¢æˆ·ç«¯åˆå§‹åŒ–é€»è¾‘ï¼‰
    :return: åˆå§‹åŒ–æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    global tracking_client
    try:
        # å®ä¾‹åŒ–ros_apiå®¢æˆ·ç«¯
        tracking_client = ros_api.TrackingDataClient(
            server_ip=ROS_SERVER_IP,
            port=ROS_SERVER_PORT
        )
        # è¿æ¥åˆ°ROSæœåŠ¡å™¨
        return tracking_client.connect_to_server()
    except Exception as e:
        print(f"[{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] âŒ è·Ÿè¸ªå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return False

def get_image_from_ros(timestamp: str) -> tuple[Image.Image, str] | tuple[None, str]:
    """
    ä»ros_apiè·å–å›¾åƒå¹¶è½¬æ¢ä¸ºPIL Imageï¼ˆæ¨¡å—åŒ–ï¼šå°è£…ROSå›¾åƒè·å–é€»è¾‘ï¼‰
    :param timestamp: æ—¶é—´æˆ³ï¼ˆç”¨äºç”Ÿæˆå›¾åƒæ–‡ä»¶åï¼‰
    :return: (PILå›¾åƒå¯¹è±¡, å›¾åƒä¿å­˜è·¯å¾„) æˆ– (None, é”™è¯¯ä¿¡æ¯)
    """
    global tracking_client
    if not tracking_client:
        return None, "è·Ÿè¸ªå®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
    
    try:
        # 1. å‘é€è¯·æ±‚åˆ°ROSæœåŠ¡å™¨
        if not tracking_client.send_request():
            return None, "å‘é€è¯·æ±‚åˆ°ROSæœåŠ¡å™¨å¤±è´¥"
        
        # 2. è§£æå­—èŠ‚æµæ•°æ®
        parsed_data = tracking_client.parse_byte_stream()
        if not parsed_data:
            return None, "è§£æROSå­—èŠ‚æµæ•°æ®å¤±è´¥"
        
        # 3. æå–OpenCVå›¾åƒ
        cv_image = parsed_data.get("current_image")
        if cv_image is None or not isinstance(cv_image, np.ndarray):
            return None, "ä»ROSæ•°æ®ä¸­æå–å›¾åƒå¤±è´¥"
        
        # 4. OpenCVå›¾åƒè½¬æ¢ä¸ºPIL Imageï¼ˆCV2: BGR â†’ PIL: RGBï¼‰
        cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(cv_image_rgb)
        
        # 5. ä¿å­˜å›¾åƒåˆ°æœ¬åœ°
        image_save_path = f"{IMAGE_SAVE_PREFIX}{timestamp}.jpg"
        pil_image.save(image_save_path)
        print(f"[{timestamp}] ğŸ’¾ ä¿å­˜å¤„ç†åå›¾åƒåˆ°: {image_save_path}ï¼ˆå°ºå¯¸ï¼š{pil_image.size}ï¼Œæ¨¡å¼ï¼š{pil_image.mode}ï¼‰")
        
        return pil_image, image_save_path
    except Exception as e:
        error_msg = f"ä»ROSè·å–å›¾åƒå¤±è´¥: {str(e)}"
        return None, error_msg

# ===================== æ¨¡å‹åŠ è½½æ¨¡å—ï¼ˆæ¨¡å—åŒ–ï¼šç‹¬ç«‹å°è£…æ¨¡å‹ç›¸å…³é€»è¾‘ï¼‰ =====================
def load_model_vlm(model_path: str = MODEL_VLM_DEFAULT):
    """
    åŠ è½½å¹¶ç¼–è¯‘AIæ¨¡å‹ï¼ˆæ¨¡å—åŒ–ï¼šå°è£…æ¨¡å‹åŠ è½½ã€ç¼–è¯‘é€»è¾‘ï¼‰
    :param model_path: æ¨¡å‹è·¯å¾„/åç§°
    """
    global processor, model_vlm
    try:
        # 1. åŠ è½½å¤„ç†å™¨
        print(f"{time.time()} > åŠ è½½æ¨¡å‹å¤„ç†å™¨: {model_path}...", flush=True)
        processor = AutoProcessor.from_pretrained(model_path)
        
        # 2. åŠ è½½æ¨¡å‹
        print(f"{time.time()} > åŠ è½½æ¨¡å‹æƒé‡...", flush=True)
        model_vlm = AutoModelForImageTextToText.from_pretrained(
            model_path,
            load_in_8bit=True
        )
        
        # 3. ç¼–è¯‘æ¨¡å‹ï¼ˆä¼˜åŒ–æ¨ç†é€Ÿåº¦ï¼‰
        print(f"{time.time()} > ç¼–è¯‘æ¨¡å‹...", flush=True)
        model_vlm = torch.compile(model_vlm)
        
        print(f"{time.time()} > âœ… VLM æ¨¡å‹åŠ è½½å¹¶ç¼–è¯‘å®Œæˆï¼", flush=True)
    except Exception as e:
        raise Exception(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

def load_model_da3(model_path = MODEL_DA3_DEFAULT):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model_da3 = DepthAnything3.from_pretrained(model_path)
    model_da3 = model_da3.to(device)
    model_da3.eval()
    print(f"{time.time()} > âœ… DA3 æ¨¡å‹åŠ è½½å¹¶ç¼–è¯‘å®Œæˆï¼", flush=True)

def load_model_sam3(model_path = MODEL_SAM3_PATH):
    model = build_sam3_image_model(
        load_from_HF=False,
        checkpoint_path=model_path
    )
    processor_sam3 = Sam3Processor(model)

# ===================== æ–‡æœ¬ç”Ÿæˆæ¨¡å—ï¼ˆæ¨¡å—åŒ–ï¼šç‹¬ç«‹å°è£…æµå¼ç”Ÿæˆé€»è¾‘ï¼‰ =====================
def generate_text_stream(text_query: str, image_path: str, timestamp: str):
    """
    æµå¼ç”Ÿæˆæ–‡æœ¬å“åº”ï¼ˆæ¨¡å—åŒ–ï¼šå°è£…æ¨¡å‹æ¨ç†ã€æµå¼è¿”å›é€»è¾‘ï¼‰
    :param text_query: æ–‡æœ¬æŸ¥è¯¢æŒ‡ä»¤
    :param image_path: å›¾åƒä¿å­˜è·¯å¾„
    :param timestamp: æ—¶é—´æˆ³
    """
    global processor, model_vlm
    if not processor or not model_vlm:
        yield f"data: {json.dumps({'text': 'âŒ æ¨¡å‹æœªåŠ è½½å®Œæˆ'})}\n\n"
        return
    
    try:
        print(f"[{timestamp}] ğŸ¤– å¼€å§‹ç”Ÿæˆæ–‡æœ¬ï¼ŒæŸ¥è¯¢: '{text_query}'")
        
        # 1. æ„å»ºå¯¹è¯æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "path": image_path},
                    {"type": "text", "text": text_query}
                ]
            },
        ]
        
        # 2. åº”ç”¨èŠå¤©æ¨¡æ¿å¹¶ç¼–ç 
        inputs = processor.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt",
        ).to(model_vlm.device, dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32)
        
        # 3. åˆå§‹åŒ–æµå¼ç”Ÿæˆå™¨
        streamer = TextIteratorStreamer(
            processor.tokenizer,
            skip_prompt=True,
            skip_special_tokens=True
        )
        
        # 4. æ„å»ºç”Ÿæˆå‚æ•°
        generation_kwargs = dict(
            inputs,
            streamer=streamer,
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=True,
            num_beams=1
        )
        
        # 5. å¯åŠ¨ç‹¬ç«‹çº¿ç¨‹æ‰§è¡Œç”Ÿæˆ
        thread = Thread(target=model_vlm.generate, kwargs=generation_kwargs)
        thread.start()
        
        # 6. æµå¼è¿”å›ç”Ÿæˆç»“æœ
        for new_text in streamer:
            if new_text:
                yield f"data: {json.dumps({'text': new_text})}\n\n"
        
        print(f"[{timestamp}] âœ… æ–‡æœ¬ç”Ÿæˆå®Œæˆ")
    except Exception as e:
        error_msg = f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {str(e)}"
        yield f"data: {json.dumps({'text': f'âŒ {error_msg}'})}\n\n"

# ===================== Flaskæ¥å£æ¨¡å—ï¼ˆæ¨¡å—åŒ–ï¼šç‹¬ç«‹å°è£…APIé€»è¾‘ï¼‰ =====================
def init_flask_app():
    """
    åˆå§‹åŒ–Flaskåº”ç”¨ï¼ˆæ¨¡å—åŒ–ï¼šå°è£…Flaské…ç½®ã€è·¯ç”±æ³¨å†Œï¼‰
    """
    global app
    app = Flask(__name__)
    CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚
    
    # æ³¨å†Œè·¯ç”±
    @app.route('/generate', methods=['POST'])
    def generate():
        # 1. è§£æè¯·æ±‚å‚æ•°
        data = request.json or {}
        text_query = data.get('text', 'Describe this image')
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            # 2. ä»ROSè·å–å›¾åƒ
            print(f"[{timestamp}] ğŸ” å¼€å§‹ä»ROSè·å–å›¾åƒ...")
            pil_image, image_path = get_image_from_ros(timestamp)
            if not pil_image:
                raise Exception(image_path)  # image_pathæ­¤æ—¶ä¸ºé”™è¯¯ä¿¡æ¯
            
            # 3. æµå¼è¿”å›ç”Ÿæˆç»“æœ
            return Response(generate_text_stream(text_query, image_path, timestamp), 
                            mimetype='text/event-stream')
        
        except Exception as e:
            error_msg = f"[{timestamp}] âŒ é”™è¯¯: {str(e)}"
            print(error_msg)
            return jsonify({'error': error_msg}), 500

# ===================== ä¸»ç¨‹åºå…¥å£ï¼ˆæ¨¡å—åŒ–ï¼šç»Ÿä¸€åè°ƒå„æ¨¡å—åˆå§‹åŒ–ä¸è¿è¡Œï¼‰ =====================
def main():
    """ä¸»ç¨‹åºï¼ˆæ¨¡å—åŒ–ï¼šåè°ƒå„æ¨¡å—åˆå§‹åŒ–ï¼Œå¯åŠ¨æœåŠ¡ï¼‰"""
    try:
        # 1. åˆå§‹åŒ–Flaskåº”ç”¨
        init_flask_app()
        
        # 2. åˆå§‹åŒ–ROSè·Ÿè¸ªå®¢æˆ·ç«¯
        if not init_tracking_client():
            raise Exception("ROSè·Ÿè¸ªå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è¿è¡Œ")
        
        # 3. åŠ è½½AIæ¨¡å‹
        load_model_vlm(MODEL_VLM_DEFAULT)
        
        # 4. å¯åŠ¨FlaskæœåŠ¡
        print(f"\n[{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] ğŸš€ FlaskæœåŠ¡å¯åŠ¨ä¸­ï¼Œåœ°å€: http://{FLASK_HOST}:{FLASK_PORT}")
        app.run(
            host=FLASK_HOST,
            port=FLASK_PORT,
            threaded=True,
            debug=False  # ç”Ÿäº§ç¯å¢ƒå…³é—­debug
        )
    except Exception as e:
        print(f"[{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}] âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        os._exit(1)
    finally:
        # æ”¶å°¾ï¼šå…³é—­ROSå®¢æˆ·ç«¯è¿æ¥
        global tracking_client
        if tracking_client:
            tracking_client.close_connection()

if __name__ == '__main__':
    main()